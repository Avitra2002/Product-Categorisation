{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from langdetect import detect\n",
    "from langdetect.lang_detect_exception import LangDetectException\n",
    "import logging\n",
    "import google.cloud.logging\n",
    "from Functions import is_english, format_date, is_valid_feedback\n",
    "from google.cloud.logging.handlers import CloudLoggingHandler\n",
    "from Classifications import classification_defined_products\n",
    "from Classifications import classification_undefined_products\n",
    "\n",
    "# Initialize Cloud Logging\n",
    "# client = google.cloud.logging.Client()\n",
    "# handler = CloudLoggingHandler(client)\n",
    "# cloud_logger = logging.getLogger('cloudLogger')\n",
    "# cloud_logger.setLevel(logging.DEBUG)\n",
    "# cloud_logger.addHandler(handler)\n",
    "\n",
    "#### FOR LOCAL TEST######\n",
    "cloud_logger = logging.getLogger('cloudLogger')\n",
    "cloud_logger.setLevel(logging.DEBUG)  # Set the logging level to DEBUG\n",
    "\n",
    "# Create a console handler and set its log level\n",
    "console_handler = logging.StreamHandler()\n",
    "console_handler.setLevel(logging.DEBUG)  # Set the console handler level to DEBUG\n",
    "\n",
    "# Define the log format\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "console_handler.setFormatter(formatter)\n",
    "\n",
    "# Add the console handler to the logger\n",
    "cloud_logger.addHandler(console_handler)\n",
    "\n",
    "#### FOR LOCAL TEST######\n",
    "\n",
    "def process_voice_call_data(file_path, product, source):\n",
    "    try:\n",
    "        data = pd.read_csv(file_path)\n",
    "        cloud_logger.info(\"Data loaded successfully.\")\n",
    "    except Exception as e:\n",
    "        cloud_logger.error(f\"Error loading data: {e}\")\n",
    "        raise\n",
    "\n",
    "    date_column = None\n",
    "    for col in data.columns:\n",
    "        try:\n",
    "            if data[col].apply(lambda x: isinstance(x, str) and '/' in x).all():\n",
    "                data[col] = data[col].apply(format_date)\n",
    "                date_column = col\n",
    "                # cloud_logger.info(f\"Date column identified and formatted: {col}\")\n",
    "                break\n",
    "        except Exception as e:\n",
    "            cloud_logger.warning(f\"Error processing column '{col}' for date format: {e}\")\n",
    "\n",
    "    if not date_column:\n",
    "        cloud_logger.warning(\"No date column identified.\")\n",
    "\n",
    "    feedback_column = None\n",
    "    for col in data.columns:\n",
    "        if 'feedback' in col.lower() or 'comments' in col.lower():\n",
    "            feedback_column = col\n",
    "            # cloud_logger.info(f\"Feedback column identified: {col}\")\n",
    "            break\n",
    "\n",
    "    if feedback_column:\n",
    "        data = data[data[feedback_column].apply(lambda x: pd.notna(x) and is_english(x))]\n",
    "    else:\n",
    "        cloud_logger.warning(\"No feedback column identified.\")\n",
    "        raise ValueError(\"Feedback column is required for processing.\")\n",
    "\n",
    "    if product != \"Others\":\n",
    "        data['Product'] = product\n",
    "        data['Subcategory'] = None\n",
    "        data['Feedback Category'] = ''\n",
    "        data['Sentiment'] = None\n",
    "        data['Sentiment Score'] = None\n",
    "        data['Source'] = source\n",
    "\n",
    "        #TODO: Classification\n",
    "        data= classification_defined_products(data)\n",
    "    \n",
    "    else:\n",
    "        data['Product'] = ''\n",
    "        data['Subcategory'] = None\n",
    "        data['Feedback Category'] = ''\n",
    "        data['Sentiment'] = None\n",
    "        data['Sentiment Score'] = None\n",
    "        data['Source'] = source\n",
    "\n",
    "        #TODO: Classification\n",
    "        data= classification_undefined_products(data)\n",
    "\n",
    "    desired_columns = ['Date', 'Feedback', 'Product', 'Subcategory', 'Feedback Category', 'Sentiment', 'Sentiment Score', 'Source']\n",
    "\n",
    "    if feedback_column:\n",
    "        data.rename(columns={feedback_column: 'Feedback'}, inplace=True)\n",
    "    \n",
    "    if date_column:\n",
    "        data.rename(columns={date_column: 'Date'}, inplace=True)\n",
    "\n",
    "    data = data.reindex(columns=desired_columns)\n",
    "\n",
    "    return data\n",
    "\n",
    "    ##TODO: Append to SQL\n",
    "\n",
    "    # output_file_path = f'/path/to/output/Transformed_{product}_{source}_Voice_Data.csv'\n",
    "    # try:\n",
    "    #     data.to_csv(output_file_path, index=False)\n",
    "    #     cloud_logger.info(f\"Data transformation complete. File saved to: {output_file_path}\")\n",
    "    # except Exception as e:\n",
    "    #     cloud_logger.error(f\"Error saving transformed data: {e}\")\n",
    "    #     raise"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
